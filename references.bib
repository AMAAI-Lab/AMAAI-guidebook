---
---

@inproceedings{cuthbert2010music21,
  title={music21: A toolkit for computer-aided musicology and symbolic music data},
  author={Cuthbert, Michael Scott and Ariza, Christopher},
  year={2010},
  booktitle={ISMIR}
}

@article{sun2017query,
  title={Query by singing/humming system based on deep learning},
  author={Sun, JQ and Lee, Seok-Pil},
  journal={Int. J. Appl. Eng. Res},
  volume={12},
  number={13},
  pages={973--4562},
  year={2017}
}

@article{huang2020pop,
  title={Pop Music Transformer: Generating Music with Rhythm and Harmony},
  author={Huang, Yu-Siang and Yang, Yi-Hsuan},
  journal={arXiv preprint arXiv:2002.00212},
  year={2020}
}

@inproceedings{chen2001music,
  title={A music recommendation system based on music data grouping and user interests},
  author={Chen, Hung-Chen and Chen, Arbee LP},
  booktitle={Proceedings of the tenth international conference on Information and knowledge management},
  pages={231--238},
  year={2001}
}

@inproceedings{merono2017midi,
  title={The MIDI linked data cloud},
  author={Mero{\~n}o-Pe{\~n}uela, Albert and Hoekstra, Rinke and Gangemi, Aldo and Bloem, Peter and de Valk, Reinier and Stringer, Bas and Janssen, Berit and de Boer, Victor and Allik, Alo and Schlobach, Stefan and others},
  booktitle={International Semantic Web Conference},
  pages={156--164},
  year={2017},
  organization={Springer}
}

@inproceedings{yamaguchi2019music,
  title={A music recommendation system based on melody creation by interactive GA},
  author={Yamaguchi, Genki and Fukumoto, Makoto},
  booktitle={2019 20th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)},
  pages={286--290},
  year={2019},
  organization={IEEE}
}

@article{kong2020large,
  title={Large-Scale MIDI-based Composer Classification},
  author={Kong, Qiuqiang and Choi, Keunwoo and Wang, Yuxuan},
  journal={arXiv preprint arXiv:2010.14805},
  year={2020}
}

@inproceedings{jiang2019melody,
  title={Melody identification in standard midi files},
  author={Jiang, Zheng and Dannenberg, Roger B},
  booktitle={Proceedings of the 16th sound \& music computing conference},
  pages={65--71},
  year={2019}
}

@inproceedings{liumei2021k,
  title={K-means clustering analysis of Chinese traditional folk music based on midi music textualization},
  author={Liumei, Zhang and Fanzhi, Jiang and Jiao, Li and Gang, Ma and Tianshi, Liu},
  booktitle={2021 6th International Conference on Intelligent Computing and Signal Processing (ICSP)},
  pages={1062--1066},
  year={2021},
  organization={IEEE}
}

@inproceedings{magalhaeschordify,
  title={CHORDIFY: THREE YEARS AFTER THE LAUNCH},
  author={Magalhaes, Jos{\'e} Pedro},
  year={2015},
  booktitle={ISMIR}
}


@ARTICLE{VAT_semi,
author={T. {Miyato} and S. {Maeda} and M. {Koyama} and S. {Ishii}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning},
year={2019},
volume={41},
number={8},
pages={1979-1993},
doi={10.1109/TPAMI.2018.2858821}
}


@inbook{ReconVAT,
author = {Cheuk, Kin Wai and Herremans, Dorien and Su, Li},
title = {ReconVAT: A Semi-Supervised Automatic Music Transcription Framework for Low-Resource Real-World Data},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474085.3475405},
abstract = {Most of the current supervised automatic music transcription (AMT) models lack the ability to generalize. This means that they have trouble transcribing real-world music recordings from diverse musical genres that are not presented in the labelled training data. In this paper, we propose a semi-supervised framework, ReconVAT, which solves this issue by leveraging the huge amount of available unlabelled music recordings. The proposed ReconVAT uses reconstruction loss and virtual adversarial training. When combined with existing U-net models for AMT, ReconVAT achieves competitive results on common benchmark datasets such as MAPS and MusicNet. For example, in the few-shot setting for the string part version of MusicNet, ReconVAT achieves F1-scores of 61.0% and 41.6% for the note-wise and note-with-offset-wise metrics respectively, which translates into an improvement of 22.2% and 62.5% compared to the supervised baseline model. Our proposed framework also demonstrates the potential of continual learning on new data, which could be useful in real-world applications whereby new data is constantly available.},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {3918â€“3926},
numpages = {9}
}


@inproceedings{cheuk2021effect,
  title={The Effect of Spectrogram Reconstruction on Automatic Music Transcription: An Alternative Approach to Improve Transcription Accuracy},
  author={Cheuk, Kin Wai and Luo, Yin-Jvun and Benetos, Emmanouil and Herremans, Dorien},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)},
  pages={9091--9098},
  year={2021},
  organization={IEEE}
}
